{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASIC NEURAL NETWORK TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_num, lr = 100000, 0.01\n",
    "errs, iters = [], []\n",
    "\n",
    "inputs = np.array([[19, 28, 37], [46, 55, 64], [73, 82, 91]], dtype=float)\n",
    "inputs /= inputs.max()\n",
    "outputs = np.array([[91, 82, 73], [64, 55, 46], [37, 28, 19]], dtype=float)\n",
    "outputs /= outputs.max()\n",
    "weights = np.random.random((inputs.shape[1],outputs.shape[1]))\n",
    "\n",
    "for iteration in range(epochs_num):\n",
    "    total_err = 0\n",
    "    for i in range(len(inputs)):\n",
    "        layer0 = inputs[i:i+1]\n",
    "        layer1 = np.dot(layer0, weights)\n",
    "        layer1_delta = outputs[i:i+1] - layer1\n",
    "        weights += lr * layer0.T.dot(layer1_delta)\n",
    "        total_err += np.sum(layer1_delta ** 2)\n",
    "    if (iteration + 1) % 1000 == 0:\n",
    "        iters.append(iteration)\n",
    "        errs.append(total_err / len(inputs))\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iters, errs)\n",
    "plt.show()\n",
    "print(\"Final loss:\", total_err / len(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIMIZED NEURAL NETWORK WITH HIDDEN LAYERS\n",
    "\n",
    "#### Activation functions\n",
    "**tanh**:\n",
    "`def tanh(x): return np.tanh(x)`\n",
    "\n",
    "**relu**:\n",
    "`def relu(x): return (x * (x > 0))`\n",
    "\n",
    "**sigmoid**:\n",
    "`def sigmoid(x): return (1 / (1 + np.exp(-x)))`\n",
    "\n",
    "**softmax**:\n",
    "`def softmax(x): return (np.exp(x) / np.sum(np.exp(x), axis = 1, keepdims = True))`\n",
    "\n",
    "\n",
    "#### Activation2Deriv functions\n",
    "**tanh2deriv**:\n",
    "`def tanh2deriv(x): return (1 - x**2) `\n",
    "\n",
    "**relu2deriv**:\n",
    "`def relu2deriv(x): return x > 0`\n",
    "\n",
    "**sigmoid2deriv**:\n",
    "`def sigmoid2deriv(x): return x * (1 - x)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def relu(x): return (x * (x > 0))\n",
    "def relu2deriv(x): return x > 0\n",
    "\n",
    "epochs_num, lr, hidsize = 100000, 0.01, 20\n",
    "errs, iters = [], []\n",
    "\n",
    "inputs = np.array([[19, 28, 37], [46, 55, 64], [73, 82, 91]], dtype=float)\n",
    "inputs /= inputs.max()\n",
    "outputs = np.array([[91, 82, 73], [64, 55, 46], [37, 28, 19]], dtype=float)\n",
    "outputs /= outputs.max()\n",
    "weights01 = np.random.random((inputs.shape[1],hidsize))\n",
    "weights12 = np.random.random((hidsize,outputs.shape[1]))\n",
    "\n",
    "for iteration in range (epochs_num):\n",
    "    total_err = 0\n",
    "    for i in range (len(inputs)):\n",
    "        layer0 = inputs[i:i+1]\n",
    "        layer1 = relu(layer0.dot(weights01))\n",
    "        dropout_mask = np.random.randint(2, size = layer1.shape)\n",
    "        layer1 *= dropout_mask\n",
    "        layer2 = layer1.dot(weights12)\n",
    "        layer2_delta = outputs[i:i+1] - layer2\n",
    "        layer1_delta = layer2_delta.dot(weights12.T) * relu2deriv(layer1) * dropout_mask\n",
    "        weights12 += lr * layer1.T.dot(layer2_delta)\n",
    "        weights01 += lr * layer0.T.dot(layer1_delta)\n",
    "        total_err += np.sum(layer2_delta ** 2)\n",
    "    if not ((iteration + 1) % 1000):\n",
    "        iters.append(iteration)\n",
    "        errs.append(total_err / len(inputs))\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iters, errs)\n",
    "plt.show()\n",
    "print(\"Final loss:\", total_err / len(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVOLUTIONAL NEURAL NETWORK (CNN)\n",
    "\n",
    "#### Approach:\n",
    "\n",
    "**Layer0 -> Layer1**\n",
    "\n",
    "Instead of taking a whole layer0 and multiplying it by weights01, we split layer0 into bunch of sections with size ```(kernel_rows, kernel_cols)```. After this, we take these sections matrix with size ```(images_n, sections_n, 1, kernels_row, kernels_column)``` and transform (flatten) it so its size becomes ```(images_n * sections_n, kernels_row * kernels_column)```, because kernels (kinda \"weights\" for finding signs in data (image mostly) ) are used to return list of probability for each sign for single section, so basically we need to pass to kernels sized something like ```(n_of_all_sections_in_images_in_batch, size_of_each_section)```, so it will return us something like ```(n_of_all_sections_in_images_in_batch, probability_for_each_sign)```\n",
    "\n",
    "\n",
    "**Layer1 -> Layer2**\n",
    "\n",
    "After we get list of probabilities for signs for each section, we reshape it in something like ```(images_n, sections_n * kernels_n)``` (it's layer1) and feed it into weights12, after which we get list of predictions for each input (image, not section!) with shape ```(images_n, output.shape[1])```\n",
    "\n",
    "\n",
    "**Calculating deltas**\n",
    "\n",
    "To get layer2_delta we just need, as always, subtract from actual output our prediction. To get layer1_delta, we need to dot layer2_delta with weights12 transposed, i.e. ```layer2_delta.dot(weights12.T)```. Also multiply it by derivative of activation function as always, and if we are using dropout_mask, multiply by it to. So by the end we should get something like ```layer1_delta = layer2_delta.dot(weights12.T) * tanh2deriv(layer1) * dropout_mask```.\n",
    "\n",
    "\n",
    "**Backpropogation**\n",
    "\n",
    "To backpropogate through weights12, we just need to dot layer1 transposed with layer2_delta and multiply it by learning rate and update weights12 by this value, so we need to write something like ```weights12 += layer1.dot(layer2_delta) * alpha```\n",
    "\n",
    "To backpropogate through kernels, we need to reshape our layer1_delta into size ```(n_of_all_sections_in_images_in_batch, probability_for_each_sign)``` and dot transposed flattened input by it and multiply it by learning rate and update kernels by this value, so we write something like ```kernels += flattened_input.T.dot(layer1_delta.reshape(#(n_of_all_sections_in_images_in_batch, probability_for_each_sign)))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "\n",
    "def tanh(x): return np.tanh(x)\n",
    "def tanh2deriv(x): return (1 - x**2)\n",
    "def softmax(x): return (np.exp(x) / np.sum(np.exp(x), axis = 1, keepdims = True))\n",
    "\n",
    "def get_image_sections (image, row_size, column_size):\n",
    "    sects = []\n",
    "    for row in range (image.shape[1] - row_size):\n",
    "        for column in range (image.shape[2] - column_size):\n",
    "            sects.append(image[:, row:row + row_size, column:column + column_size].reshape(-1, 1, row_size, column_size))\n",
    "    return sects\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "train_size, test_size = 1000, 3000\n",
    "\n",
    "train_images, train_labels = (x_train[0:train_size].reshape(train_size, 28*28) / 255, np.zeros((len(y_train[0:train_size]),10)))\n",
    "for i,j in enumerate(y_train[0:train_size]):\n",
    "    train_labels[i][j] = 1\n",
    "\n",
    "test_images, test_labels = (x_test[0:test_size].reshape(test_size, 28*28) / 255, np.zeros((len(y_test[0:test_size]), 10)))\n",
    "for i,j in enumerate(y_test[0:test_size]):\n",
    "    test_labels[i][j] = 1\n",
    "\n",
    "row_size, column_size, kernels_n = 3, 3, 16\n",
    "hidsize = (28 - row_size) * (28 - column_size) * kernels_n\n",
    "\n",
    "kernels = 0.02 * np.random.random((row_size * column_size, kernels_n)) - 0.01\n",
    "weights12 = 0.2 * np.random.random((hidsize, 10)) - 0.1\n",
    "\n",
    "iterations, alpha, batch_size = 100000, 2, 100\n",
    "test_accuracy, train_accuracy, iters = [], []\n",
    "\n",
    "for iteration in range (iterations):\n",
    "    for batch_index in range (train_images.shape[0]//batch_size):\n",
    "        layer0 = train_images[batch_index * batch_size : (batch_index + 1) * batch_size].reshape(-1, 28, 28)\n",
    "        sects = get_image_sections(layer0, row_size, column_size)\n",
    "        expanded_input = np.concatenate(sects, axis = 1)\n",
    "        flattened_input = expanded_input.reshape(expanded_input.shape[0] * expanded_input.shape[1], -1)\n",
    "        layer1 = tanh(flattened_input.dot(kernels)).reshape(batch_size, -1)\n",
    "        dropout_mask = np.random.randint(2, size=layer1.shape)\n",
    "        layer1 *= dropout_mask * 2\n",
    "        layer2 = softmax(layer1.reshape(batch_size, -1).dot(weights12))\n",
    "        layer2_delta = (train_labels[batch_index * batch_size : (batch_index + 1) * batch_size] - layer2) / (batch_size * layer2.shape[0])\n",
    "        layer1_delta = layer2.dot(weights12.T) * dropout_mask * tanh2deriv(layer1)\n",
    "        weights12 += layer1.T.dot(layer2_delta) * alpha\n",
    "        kernels += flattened_input.T.dot(layer1_delta.reshape(-1, kernels_n)) * alpha\n",
    "        \n",
    "    if not ((iteration + 1) % 1000):\n",
    "        train_correct_cnt = 0\n",
    "        for image in range (train_images):\n",
    "            layer0 = train_images[image:image + 1].reshape(-1, 28, 28)\n",
    "            sects = get_image_sections(layer0, row_size, column_size)\n",
    "            expanded_input = np.concatenate(sects, axis = 1)\n",
    "            flattened_input = expanded_input.reshape(expanded_input.shape[0] * expanded_input.shape[1], -1)\n",
    "            layer1 = tanh(flattened_input.dot(kernels).reshape(1, -1))\n",
    "            layer2 = layer1.dot(weights12)\n",
    "            train_correct_cnt += int(np.argmax(layer2) == np.argmax(train_labels[image:image + 1]))            \n",
    "        test_correct_cnt = 0\n",
    "        for image in range (len(test_images)):\n",
    "            layer0 = test_images[image:image + 1].reshape(-1, 28, 28)\n",
    "            sects = get_image_sections(layer0, row_size, column_size)\n",
    "            expanded_input = np.concatenate(sects, axis = 1)\n",
    "            flattened_input = expanded_input.reshape(expanded_input.shape[0] * expanded_input.shape[1], -1)\n",
    "            layer1 = tanh(flattened_input.dot(kernels).reshape(1, -1))\n",
    "            layer2 = layer1.dot(weights12)\n",
    "            test_correct_cnt += int(np.argmax(layer2) == np.argmax(test_labels[image:image + 1]))\n",
    "        print(test_correct_cnt)\n",
    "        test_accuracy.append(test_correct_cnt / test_size)\n",
    "        train_accuracy.append(train_accuracy / train_size)\n",
    "        iters.append(iteration)\n",
    "        \n",
    "plt.plot(iters, test_accuracy, label = \"Test_acc\")\n",
    "plt.plot(iters, train_accuracy, label = \"Train_acc\")\n",
    "plt.show()\n",
    "print(f\"Final test accuracy: {correct_cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION TO NLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x): return (1 / (1 + np.exp(-x)))\n",
    "\n",
    "train_input = [\"it has fur\", \"its fur is really nice\", \"you are a nice guy\", \"she is talkative\", \"good boy\"]\n",
    "train_output = [1, 1, 0, 0, 1]\n",
    "\n",
    "allwords = set(list(\" \".join(train_input).split()))\n",
    "vocab = {}\n",
    "\n",
    "for i, word in enumerate(allwords):\n",
    "    vocab[word] = i\n",
    "\n",
    "iterations, alpha, hidsize = 100000, 0.1, 30\n",
    "\n",
    "weights01 = 0.2 * np.random.random((len(vocab), hidsize)) - 0.1\n",
    "weights12 = 0.2 * np.random.random((hidsize, 1)) - 0.1\n",
    "\n",
    "for iteration in range (iterations):\n",
    "    for input in range (len(train_input)):\n",
    "        layer0 = []\n",
    "        for word in train_input[input].split():\n",
    "            layer0.append(vocab[word])\n",
    "        layer1 = sigmoid(np.sum(weights01[layer0],axis = 0))\n",
    "        layer2 = sigmoid(layer1.dot(weights12))\n",
    "\n",
    "        layer2_delta = train_output[input] - layer2\n",
    "        layer1_delta = layer2_delta.dot(weights12.T)\n",
    "\n",
    "        weights12 += np.outer(layer1, layer2_delta) * alpha\n",
    "        weights01[layer0] += layer1_delta * alpha\n",
    "\n",
    "        print(layer2_delta**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAG OF WORDS (MISSING WORD PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "def sigmoid ( x ) : return ( 1 / ( 1 + np.exp ( -x ) ) )\n",
    "def find_similar ( target ) : \n",
    "    scores = Counter ( )\n",
    "    for word, index in vocab.items ( ) :\n",
    "        scores [ word ] = - math.sqrt ( sum ( ( weights01 [ vocab [ target ] ] - weights01 [ index ] ) ** 2 ) )\n",
    "    return scores.most_common ( 10 )\n",
    "f = open ( 'reviews.txt' )\n",
    "raw_reviews = f.readlines ( )\n",
    "f.close ( )\n",
    "allwords = list ( set ( \" \".join ( raw_reviews ) .split ( ) ) )\n",
    "vocab = { }\n",
    "for index, word in enumerate ( allwords ) :\n",
    "    vocab [ word ] = index\n",
    "input_data = [ ]\n",
    "concatenated_data = [ ]\n",
    "for review in raw_reviews:\n",
    "    sequence_data = [ ]\n",
    "    for word in review.split ( ) :\n",
    "        sequence_data.append ( vocab [ word ] )\n",
    "        concatenated_data.append ( vocab [ word ] )\n",
    "    input_data.append ( sequence_data )\n",
    "concatenated_data = np.array ( concatenated_data )\n",
    "hidden_size, negative_size, context_windows_size, iterations, alpha = 30, 8, 4, 3, 0.05\n",
    "weights01 = np.random.rand ( len ( vocab ), hidden_size )\n",
    "weights12 = np.random.rand ( len ( vocab ), hidden_size )\n",
    "last_layer_target = np.zeros ( negative_size + 1 )\n",
    "last_layer_target [ 0 ] = 1\n",
    "for iteration, input_sequence in enumerate ( input_data * iterations ):\n",
    "    for target in range ( len ( input_sequence ) ):\n",
    "        chosen_words = [ input_sequence [ target ] ] + concatenated_data [ ( np.random.random ( negative_size ) * len ( concatenated_data ) ) .astype('int') ] .tolist()\n",
    "        layer_0 = input_sequence [ max ( 0, target - context_windows_size ) : target ] + input_sequence [ target + 1 : min ( len ( input_sequence ) , target + 1 + context_windows_size ) ]\n",
    "        layer_1 = np.mean ( weights01 [ layer_0 ] , axis = 0 )\n",
    "        layer_2 = sigmoid ( layer_1.dot ( weights12 [ chosen_words ] .T ) ) \n",
    "        layer_2_delta = layer_2 - last_layer_target\n",
    "        layer_1_delta = layer_2_delta.dot ( weights12 [ chosen_words ] )\n",
    "        weights01 [ layer_0 ] -= layer_1_delta * alpha\n",
    "        weights12 [ chosen_words ] -= np.outer ( layer_2_delta, layer_1 ) * alpha\n",
    "    if not iteration % 5000:\n",
    "        print ( f\"Progress: { iteration } / { len ( input_data * iterations ) }\" )\n",
    "        print ( find_similar ( \"beautiful\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECURRENT NEURAL NETWORK (RNN) (MISSING WORD PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 83.07716653366394\n",
      "['where', 'is', 'mary?', '\\tgarden\\t11']\n",
      "True: is  Prediction: kitchen. \n",
      "True: mary?  Prediction: \thallway\t2 \n",
      "True: \tgarden\t11  Prediction: \tgarden\t14 \n",
      "Perplexity: 82.72856350062432\n",
      "['john', 'went', 'back', 'to', 'the', 'bathroom.']\n",
      "True: went  Prediction: \thallway\t13 \n",
      "True: back  Prediction: \toffice\t2 \n",
      "True: to  Prediction: \toffice\t2 \n",
      "True: the  Prediction: the \n",
      "True: bathroom.  Prediction: the \n",
      "Perplexity: 82.82384944279562\n",
      "['mary', 'went', 'to', 'the', 'kitchen.']\n",
      "True: went  Prediction: \toffice\t5 \n",
      "True: to  Prediction: \toffice\t5 \n",
      "True: the  Prediction: \tgarden\t10 \n",
      "True: kitchen.  Prediction: the \n",
      "Perplexity: 82.71018252125117\n",
      "['sandra', 'went', 'to', 'the', 'bedroom.']\n",
      "True: went  Prediction: the \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: the \n",
      "Perplexity: 81.84271188042023\n",
      "['daniel', 'went', 'back', 'to', 'the', 'hallway.']\n",
      "True: went  Prediction: the \n",
      "True: back  Prediction: the \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: the \n",
      "True: hallway.  Prediction: the \n",
      "Perplexity: 82.53142035292866\n",
      "['daniel', 'went', 'to', 'the', 'garden.']\n",
      "True: went  Prediction: the \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: the \n",
      "True: garden.  Prediction: the \n",
      "Perplexity: 80.14727700436708\n",
      "['where', 'is', 'mary?', '\\thallway\\t5']\n",
      "True: is  Prediction: the \n",
      "True: mary?  Prediction: the \n",
      "True: \thallway\t5  Prediction: the \n",
      "Perplexity: 72.72900292075309\n",
      "['daniel', 'travelled', 'to', 'the', 'kitchen.']\n",
      "True: travelled  Prediction: the \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: the \n",
      "Perplexity: 84.71753043675912\n",
      "['daniel', 'journeyed', 'to', 'the', 'hallway.']\n",
      "True: journeyed  Prediction: the \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: the \n",
      "True: hallway.  Prediction: the \n",
      "Perplexity: 31.572343059073862\n",
      "['where', 'is', 'mary?', '\\thallway\\t2']\n",
      "True: is  Prediction: the \n",
      "True: mary?  Prediction: the \n",
      "True: \thallway\t2  Prediction: the \n",
      "Perplexity: 24.15806352347668\n",
      "['where', 'is', 'sandra?', '\\tbedroom\\t5']\n",
      "True: is  Prediction: the \n",
      "True: sandra?  Prediction: the \n",
      "True: \tbedroom\t5  Prediction: the \n",
      "Perplexity: 93.30252662027283\n",
      "['daniel', 'travelled', 'to', 'the', 'bedroom.']\n",
      "True: travelled  Prediction: the \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: the \n",
      "Perplexity: 24.30312163131773\n",
      "['daniel', 'moved', 'to', 'the', 'kitchen.']\n",
      "True: moved  Prediction: to \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: the \n",
      "Perplexity: 18.853373449885403\n",
      "['sandra', 'went', 'back', 'to', 'the', 'hallway.']\n",
      "True: went  Prediction: to \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: the \n",
      "True: hallway.  Prediction: the \n",
      "Perplexity: 77.20483090159787\n",
      "['mary', 'journeyed', 'to', 'the', 'kitchen.']\n",
      "True: journeyed  Prediction: to \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: the \n",
      "Perplexity: 12.65382772358953\n",
      "['where', 'is', 'daniel?', '\\thallway\\t5']\n",
      "True: is  Prediction: to \n",
      "True: daniel?  Prediction: to \n",
      "True: \thallway\t5  Prediction: the \n",
      "Perplexity: 9.132802857063595\n",
      "['where', 'is', 'john?', '\\tgarden\\t11']\n",
      "True: is  Prediction: to \n",
      "True: john?  Prediction: to \n",
      "True: \tgarden\t11  Prediction: the \n",
      "Perplexity: 35.27808780242173\n",
      "['mary', 'journeyed', 'to', 'the', 'kitchen.']\n",
      "True: journeyed  Prediction: to \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: garden. \n",
      "Perplexity: 10.331590786140449\n",
      "['mary', 'went', 'back', 'to', 'the', 'garden.']\n",
      "True: went  Prediction: to \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: kitchen. \n",
      "True: garden.  Prediction: bedroom. \n",
      "Perplexity: 7.3577567226974\n",
      "['where', 'is', 'john?', '\\toffice\\t5']\n",
      "True: is  Prediction: to \n",
      "True: john?  Prediction: the \n",
      "True: \toffice\t5  Prediction: the \n",
      "Perplexity: 20.945827219375104\n",
      "['where', 'is', 'mary?', '\\tbathroom\\t11']\n",
      "True: is  Prediction: to \n",
      "True: mary?  Prediction: the \n",
      "True: \tbathroom\t11  Prediction: the \n",
      "Perplexity: 9.102223909806687\n",
      "['mary', 'went', 'back', 'to', 'the', 'bathroom.']\n",
      "True: went  Prediction: to \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: the \n",
      "True: bathroom.  Prediction: bedroom. \n",
      "Perplexity: 6.334879963336347\n",
      "['where', 'is', 'daniel?', '\\tgarden\\t4']\n",
      "True: is  Prediction: to \n",
      "True: daniel?  Prediction: to \n",
      "True: \tgarden\t4  Prediction: the \n",
      "Perplexity: 14.83434929511075\n",
      "['mary', 'travelled', 'to', 'the', 'garden.']\n",
      "True: travelled  Prediction: is \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: garden.  Prediction: garden. \n",
      "Perplexity: 7.875146252602628\n",
      "['sandra', 'journeyed', 'to', 'the', 'kitchen.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: kitchen. \n",
      "Perplexity: 5.394784702270227\n",
      "['daniel', 'journeyed', 'to', 'the', 'bedroom.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: kitchen. \n",
      "Perplexity: 8.706810640819342\n",
      "['sandra', 'moved', 'to', 'the', 'garden.']\n",
      "True: moved  Prediction: is \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: garden.  Prediction: garden. \n",
      "Perplexity: 7.152764044217229\n",
      "['mary', 'moved', 'to', 'the', 'bedroom.']\n",
      "True: moved  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: kitchen. \n",
      "Perplexity: 4.556861046803219\n",
      "['where', 'is', 'sandra?', '\\toffice\\t11']\n",
      "True: is  Prediction: is \n",
      "True: sandra?  Prediction: john? \n",
      "True: \toffice\t11  Prediction: \tbedroom\t8 \n",
      "Perplexity: 6.152514501661463\n",
      "['sandra', 'went', 'to', 'the', 'kitchen.']\n",
      "True: went  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: garden. \n",
      "Perplexity: 6.63674002979079\n",
      "['daniel', 'journeyed', 'to', 'the', 'bedroom.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: kitchen. \n",
      "Perplexity: 4.104600145363678\n",
      "['where', 'is', 'sandra?', '\\tgarden\\t14']\n",
      "True: is  Prediction: is \n",
      "True: sandra?  Prediction: john? \n",
      "True: \tgarden\t14  Prediction: \tbedroom\t8 \n",
      "Perplexity: 5.56319401088751\n",
      "['sandra', 'went', 'to', 'the', 'office.']\n",
      "True: went  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: garden. \n",
      "Perplexity: 6.087273196940601\n",
      "['john', 'moved', 'to', 'the', 'office.']\n",
      "True: moved  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: kitchen. \n",
      "Perplexity: 3.7790212437599164\n",
      "['sandra', 'went', 'to', 'the', 'office.']\n",
      "True: went  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: kitchen. \n",
      "Perplexity: 5.281899325383393\n",
      "['daniel', 'travelled', 'to', 'the', 'hallway.']\n",
      "True: travelled  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: hallway.  Prediction: garden. \n",
      "Perplexity: 5.6885837913355\n",
      "['daniel', 'moved', 'to', 'the', 'bathroom.']\n",
      "True: moved  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bathroom.  Prediction: kitchen. \n",
      "Perplexity: 3.5706263980100474\n",
      "['where', 'is', 'mary?', '\\tgarden\\t11']\n",
      "True: is  Prediction: is \n",
      "True: mary?  Prediction: john? \n",
      "True: \tgarden\t11  Prediction: \tbedroom\t8 \n",
      "Perplexity: 5.096799332787803\n",
      "['daniel', 'moved', 'to', 'the', 'office.']\n",
      "True: moved  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: garden. \n",
      "Perplexity: 5.383859032320686\n",
      "['mary', 'went', 'back', 'to', 'the', 'office.']\n",
      "True: went  Prediction: went \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: garden. \n",
      "Perplexity: 3.4150678000818004\n",
      "['daniel', 'went', 'to', 'the', 'hallway.']\n",
      "True: went  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: hallway.  Prediction: kitchen. \n",
      "Perplexity: 4.978742659855068\n",
      "['where', 'is', 'john?', '\\thallway\\t10']\n",
      "True: is  Prediction: is \n",
      "True: john?  Prediction: mary? \n",
      "True: \thallway\t10  Prediction: \thallway\t5 \n",
      "Perplexity: 5.167016014225585\n",
      "['daniel', 'journeyed', 'to', 'the', 'bathroom.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bathroom.  Prediction: kitchen. \n",
      "Perplexity: 3.302099128324781\n",
      "['where', 'is', 'sandra?', '\\tbedroom\\t2']\n",
      "True: is  Prediction: is \n",
      "True: sandra?  Prediction: john? \n",
      "True: \tbedroom\t2  Prediction: \tbedroom\t8 \n",
      "Perplexity: 4.89392084906672\n",
      "['sandra', 'journeyed', 'to', 'the', 'bedroom.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: garden. \n",
      "Perplexity: 4.967749540111603\n",
      "['where', 'is', 'daniel?', '\\toffice\\t11']\n",
      "True: is  Prediction: is \n",
      "True: daniel?  Prediction: john? \n",
      "True: \toffice\t11  Prediction: \tkitchen\t5 \n",
      "Perplexity: 3.2204667980920325\n",
      "['mary', 'travelled', 'to', 'the', 'kitchen.']\n",
      "True: travelled  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: kitchen. \n",
      "Perplexity: 4.82697743233106\n",
      "['mary', 'went', 'back', 'to', 'the', 'bathroom.']\n",
      "True: went  Prediction: went \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: the \n",
      "True: the  Prediction: the \n",
      "True: bathroom.  Prediction: garden. \n",
      "Perplexity: 4.798983866629368\n",
      "['sandra', 'journeyed', 'to', 'the', 'kitchen.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: kitchen. \n",
      "Perplexity: 3.158563360452329\n",
      "['where', 'is', 'sandra?', '\\tbedroom\\t2']\n",
      "True: is  Prediction: is \n",
      "True: sandra?  Prediction: john? \n",
      "True: \tbedroom\t2  Prediction: \tbedroom\t8 \n",
      "Perplexity: 4.764026189904645\n",
      "['where', 'is', 'john?', '\\tgarden\\t10']\n",
      "True: is  Prediction: is \n",
      "True: john?  Prediction: mary? \n",
      "True: \tgarden\t10  Prediction: \thallway\t5 \n",
      "Perplexity: 4.658345864843041\n",
      "['where', 'is', 'mary?', '\\toffice\\t8']\n",
      "True: is  Prediction: is \n",
      "True: mary?  Prediction: john? \n",
      "True: \toffice\t8  Prediction: \tkitchen\t5 \n",
      "Perplexity: 3.114830787083371\n",
      "['where', 'is', 'daniel?', '\\tbedroom\\t2']\n",
      "True: is  Prediction: is \n",
      "True: daniel?  Prediction: john? \n",
      "True: \tbedroom\t2  Prediction: \tbedroom\t8 \n",
      "Perplexity: 4.703302214626646\n",
      "['sandra', 'journeyed', 'to', 'the', 'bathroom.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bathroom.  Prediction: garden. \n",
      "Perplexity: 4.537935010088232\n",
      "['john', 'went', 'to', 'the', 'kitchen.']\n",
      "True: went  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: kitchen. \n",
      "Perplexity: 3.081958543503036\n",
      "['sandra', 'travelled', 'to', 'the', 'kitchen.']\n",
      "True: travelled  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: kitchen. \n",
      "Perplexity: 4.649524075408475\n",
      "['mary', 'went', 'to', 'the', 'kitchen.']\n",
      "True: went  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: garden. \n",
      "Perplexity: 4.434253198325913\n",
      "['john', 'journeyed', 'to', 'the', 'kitchen.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: kitchen. \n",
      "Perplexity: 3.0569992678340085\n",
      "['where', 'is', 'sandra?', '\\thallway\\t11']\n",
      "True: is  Prediction: is \n",
      "True: sandra?  Prediction: john? \n",
      "True: \thallway\t11  Prediction: \tbedroom\t8 \n",
      "Perplexity: 4.601033534291295\n",
      "['where', 'is', 'john?', '\\tbathroom\\t2']\n",
      "True: is  Prediction: is \n",
      "True: john?  Prediction: john? \n",
      "True: \tbathroom\t2  Prediction: \thallway\t5 \n",
      "Perplexity: 4.3642463177038255\n",
      "['sandra', 'went', 'back', 'to', 'the', 'office.']\n",
      "True: went  Prediction: went \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: bedroom. \n",
      "Perplexity: 3.034752183841395\n",
      "['where', 'is', 'sandra?', '\\toffice\\t5']\n",
      "True: is  Prediction: is \n",
      "True: sandra?  Prediction: john? \n",
      "True: \toffice\t5  Prediction: \tbedroom\t8 \n",
      "Perplexity: 4.557164432894178\n",
      "['john', 'went', 'to', 'the', 'bedroom.']\n",
      "True: went  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: garden. \n",
      "Perplexity: 4.302716899328688\n",
      "['sandra', 'journeyed', 'to', 'the', 'bedroom.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: kitchen. \n",
      "Perplexity: 3.018093033801653\n",
      "['where', 'is', 'john?', '\\tgarden\\t8']\n",
      "True: is  Prediction: is \n",
      "True: john?  Prediction: john? \n",
      "True: \tgarden\t8  Prediction: \tbedroom\t8 \n",
      "Perplexity: 4.529975125536428\n",
      "['where', 'is', 'john?', '\\thallway\\t4']\n",
      "True: is  Prediction: is \n",
      "True: john?  Prediction: john? \n",
      "True: \thallway\t4  Prediction: \thallway\t5 \n",
      "Perplexity: 4.230509196923507\n",
      "['daniel', 'journeyed', 'to', 'the', 'office.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: kitchen. \n",
      "Perplexity: 3.0031400671255866\n",
      "['sandra', 'moved', 'to', 'the', 'bedroom.']\n",
      "True: moved  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: bedroom. \n",
      "Perplexity: 4.516095445512619\n",
      "['john', 'journeyed', 'to', 'the', 'office.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: garden. \n",
      "Perplexity: 4.145538265047718\n",
      "['where', 'is', 'daniel?', '\\tbedroom\\t13']\n",
      "True: is  Prediction: is \n",
      "True: daniel?  Prediction: daniel? \n",
      "True: \tbedroom\t13  Prediction: \tkitchen\t5 \n",
      "Perplexity: 2.993870363314145\n",
      "['where', 'is', 'sandra?', '\\tgarden\\t5']\n",
      "True: is  Prediction: is \n",
      "True: sandra?  Prediction: john? \n",
      "True: \tgarden\t5  Prediction: \tbedroom\t8 \n",
      "Perplexity: 4.49935226655437\n",
      "['where', 'is', 'mary?', '\\thallway\\t1']\n",
      "True: is  Prediction: is \n",
      "True: mary?  Prediction: john? \n",
      "True: \thallway\t1  Prediction: \thallway\t5 \n",
      "Perplexity: 4.046895439080304\n",
      "['mary', 'journeyed', 'to', 'the', 'kitchen.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: kitchen. \n",
      "Perplexity: 2.9906281913364743\n",
      "['john', 'travelled', 'to', 'the', 'hallway.']\n",
      "True: travelled  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: hallway.  Prediction: bedroom. \n",
      "Perplexity: 4.493256312980203\n",
      "['sandra', 'went', 'back', 'to', 'the', 'bedroom.']\n",
      "True: went  Prediction: went \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: garden. \n",
      "Perplexity: 3.966359418628243\n",
      "['sandra', 'journeyed', 'to', 'the', 'bedroom.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: kitchen. \n",
      "Perplexity: 2.9792938386999026\n",
      "['mary', 'went', 'to', 'the', 'bedroom.']\n",
      "True: went  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bedroom.  Prediction: kitchen. \n",
      "Perplexity: 4.483748112655559\n",
      "['daniel', 'journeyed', 'to', 'the', 'kitchen.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: garden. \n",
      "Perplexity: 3.944865164659655\n",
      "['where', 'is', 'daniel?', '\\tkitchen\\t8']\n",
      "True: is  Prediction: is \n",
      "True: daniel?  Prediction: daniel? \n",
      "True: \tkitchen\t8  Prediction: \tkitchen\t5 \n",
      "Perplexity: 2.9697434943677803\n",
      "['mary', 'went', 'back', 'to', 'the', 'office.']\n",
      "True: went  Prediction: went \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: bedroom. \n",
      "Perplexity: 4.48012542642737\n",
      "['where', 'is', 'daniel?', '\\tgarden\\t11']\n",
      "True: is  Prediction: is \n",
      "True: daniel?  Prediction: john? \n",
      "True: \tgarden\t11  Prediction: \thallway\t5 \n",
      "Perplexity: 3.9426623063394683\n",
      "['where', 'is', 'john?', '\\thallway\\t2']\n",
      "True: is  Prediction: is \n",
      "True: john?  Prediction: daniel? \n",
      "True: \thallway\t2  Prediction: \tkitchen\t5 \n",
      "Perplexity: 2.974588083136721\n",
      "['where', 'is', 'mary?', '\\thallway\\t1']\n",
      "True: is  Prediction: is \n",
      "True: mary?  Prediction: john? \n",
      "True: \thallway\t1  Prediction: \tbedroom\t8 \n",
      "Perplexity: 4.543005086238054\n",
      "['john', 'journeyed', 'to', 'the', 'bathroom.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bathroom.  Prediction: garden. \n",
      "Perplexity: 3.8923444667226836\n",
      "['john', 'journeyed', 'to', 'the', 'bathroom.']\n",
      "True: journeyed  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bathroom.  Prediction: kitchen. \n",
      "Perplexity: 2.9647667694122792\n",
      "['john', 'travelled', 'to', 'the', 'office.']\n",
      "True: travelled  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: bedroom. \n",
      "Perplexity: 4.600184029523478\n",
      "['sandra', 'went', 'back', 'to', 'the', 'office.']\n",
      "True: went  Prediction: went \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: garden. \n",
      "Perplexity: 3.858820516507641\n",
      "['mary', 'went', 'to', 'the', 'kitchen.']\n",
      "True: went  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: kitchen. \n",
      "Perplexity: 2.951155265951217\n",
      "['john', 'went', 'to', 'the', 'hallway.']\n",
      "True: went  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: hallway.  Prediction: bedroom. \n",
      "Perplexity: 4.625620858596894\n",
      "['sandra', 'moved', 'to', 'the', 'office.']\n",
      "True: moved  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: office.  Prediction: garden. \n",
      "Perplexity: 3.8417172846489116\n",
      "['john', 'went', 'back', 'to', 'the', 'bathroom.']\n",
      "True: went  Prediction: went \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bathroom.  Prediction: bedroom. \n",
      "Perplexity: 2.9440873960691203\n",
      "['sandra', 'moved', 'to', 'the', 'garden.']\n",
      "True: moved  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: garden.  Prediction: bedroom. \n",
      "Perplexity: 4.645847807155703\n",
      "['mary', 'went', 'back', 'to', 'the', 'hallway.']\n",
      "True: went  Prediction: went \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: hallway.  Prediction: garden. \n",
      "Perplexity: 3.8307980730792655\n",
      "['where', 'is', 'sandra?', '\\tbathroom\\t5']\n",
      "True: is  Prediction: is \n",
      "True: sandra?  Prediction: daniel? \n",
      "True: \tbathroom\t5  Prediction: \tkitchen\t5 \n",
      "Perplexity: 2.9378693793156345\n",
      "['where', 'is', 'john?', '\\tkitchen\\t5']\n",
      "True: is  Prediction: is \n",
      "True: john?  Prediction: john? \n",
      "True: \tkitchen\t5  Prediction: \tbedroom\t8 \n",
      "Perplexity: 4.663763727888122\n",
      "['sandra', 'moved', 'to', 'the', 'kitchen.']\n",
      "True: moved  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: garden. \n",
      "Perplexity: 3.82128115204923\n",
      "['sandra', 'went', 'back', 'to', 'the', 'bathroom.']\n",
      "True: went  Prediction: went \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bathroom.  Prediction: bedroom. \n",
      "Perplexity: 2.931751173558325\n",
      "['john', 'travelled', 'to', 'the', 'kitchen.']\n",
      "True: travelled  Prediction: went \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: kitchen.  Prediction: bedroom. \n",
      "Perplexity: 4.679768790064525\n",
      "['mary', 'went', 'back', 'to', 'the', 'hallway.']\n",
      "True: went  Prediction: went \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: hallway.  Prediction: garden. \n",
      "Perplexity: 3.812805668186074\n",
      "['john', 'went', 'back', 'to', 'the', 'bathroom.']\n",
      "True: went  Prediction: went \n",
      "True: back  Prediction: to \n",
      "True: to  Prediction: to \n",
      "True: the  Prediction: the \n",
      "True: bathroom.  Prediction: bedroom. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def softmax ( x ) : return np.exp ( x - np.max ( x ) ) / np.exp ( x - np.max ( x ) ) .sum ( axis=0 )\n",
    "\n",
    "f = open ( \"qa1_single-supporting-fact_train.txt\", 'r' )\n",
    "raw_data = f.readlines ( )\n",
    "f.close ( )\n",
    "input_data_raw = list ( )\n",
    "for sentence in raw_data:\n",
    "    input_data_raw.append ( sentence.lower ( ) .replace ( \"\\n\",\"\" ) .split ( \" \" ) [ 1: ] )\n",
    "allwords = set ( )\n",
    "for sentence in input_data_raw:\n",
    "    for word in sentence:\n",
    "        allwords.add ( word )\n",
    "\n",
    "vocab = { }\n",
    "for index, word in enumerate ( allwords ):\n",
    "    vocab [ word ] = index\n",
    "\n",
    "input_data = []\n",
    "for sentence in input_data_raw:\n",
    "    sentence_data = list ( )\n",
    "    for word in sentence:\n",
    "        sentence_data.append ( vocab [ word ] )\n",
    "    input_data.append ( sentence_data )\n",
    "\n",
    "embeding_size = 10\n",
    "\n",
    "start = np.zeros ( embeding_size )  \n",
    "prediction_weights = ( np.random.random ( ( embeding_size, len ( vocab ) ) ) - 0.5 ) * 0.1\n",
    "recurrent = np.eye ( embeding_size )\n",
    "embeddings = ( np.random.random ( ( len ( vocab ) ,  embeding_size ) ) - 0.5 ) * 0.1\n",
    "onehots = np.eye ( len ( vocab ) )\n",
    "iterations = 100000\n",
    "alpha = 0.001\n",
    "for iteration in range ( iterations ) :\n",
    "    loss = 0\n",
    "    input_sequence = input_data [ iteration % len ( input_data ) ]\n",
    "    layers = list ( )\n",
    "    layer = { }\n",
    "    layer [ 'hidden' ] = start\n",
    "    layers.append ( layer )\n",
    "    for new_word in input_sequence:\n",
    "        layer = { }\n",
    "        layer [ 'prediction' ] = softmax ( layers [ -1 ] [ 'hidden' ] .dot ( prediction_weights ) )\n",
    "        layer [ 'prediction_target' ] = new_word\n",
    "        loss += -np.log ( layer [ 'prediction' ] [ new_word ] ) \n",
    "        layer [ 'hidden' ] = layers [ -1 ] [ 'hidden' ] .dot ( recurrent ) + embeddings [ new_word ]\n",
    "        layers.append ( layer )\n",
    "    for layer_i in reversed ( range ( len ( layers ) ) ) : \n",
    "        layer = layers [ layer_i ]\n",
    "        if layer_i > 0:\n",
    "            layer [ 'output_delta' ] = layer [ 'prediction' ] - onehots [ layer [ 'prediction_target' ] ]\n",
    "            prediction_delta = layer [ 'output_delta' ] .dot ( prediction_weights.T )\n",
    "            if layer_i == len ( layers ) - 1:\n",
    "                layer [ 'hidden_delta' ] = prediction_delta\n",
    "            else:\n",
    "                layer [ 'hidden_delta' ] = prediction_delta + layers [ layer_i + 1 ] [ 'hidden_delta' ] .dot ( recurrent.T )\n",
    "        else:\n",
    "            layer [ 'hidden_delta' ] = layers [ layer_i + 1 ] [ 'hidden_delta' ] .dot ( recurrent.T )\n",
    "    start -= layers [ 0 ] [ 'hidden_delta' ] * alpha / float ( len ( input_sequence ) )\n",
    "    for prevlayer_i, layer in enumerate ( layers [ 1: ] ) :\n",
    "        prediction_weights -= np.outer ( layers [ prevlayer_i ] [ 'hidden' ], layer [ 'output_delta' ] ) * alpha / float ( len ( input_sequence ) )\n",
    "        embeddings_i = input_sequence [ prevlayer_i ]\n",
    "        embeddings [ embeddings_i ] -= layer [ 'hidden_delta' ] * alpha / float ( len ( input_sequence ) )\n",
    "        recurrent -= np.outer ( layers [ prevlayer_i ] [ 'hidden' ], layer [ 'hidden_delta' ] ) * alpha / float ( len ( input_sequence ) )\n",
    "    if not ( iteration % 1000 ) :\n",
    "        print ( f\"Perplexity: { np.exp ( loss/len ( input_sequence ) ) }\" )\n",
    "        trues = list()\n",
    "        preds = list()\n",
    "        layers = list ( )\n",
    "        layer = { }\n",
    "        layer [ 'hidden' ] = start\n",
    "        layers.append ( layer )\n",
    "        sequence_i = random.randint ( 0, len ( input_data ) ) \n",
    "        print ( input_data_raw [ sequence_i ] )\n",
    "        for new_word in input_data [ sequence_i ] :\n",
    "            layer = { }\n",
    "            layer [ 'prediction' ] = softmax ( layers [ -1 ] [ 'hidden' ] .dot ( prediction_weights ) )\n",
    "            trues.append ( list ( vocab.keys ( ) ) [ list ( vocab.values ( ) ) .index ( new_word ) ] )\n",
    "            preds.append ( list ( vocab.keys ( ) ) [ list ( vocab.values ( ) ) .index ( layer [ 'prediction' ] .argmax ( ) ) ] ) \n",
    "            layer [ 'hidden' ] = layers [ -1 ] [ 'hidden' ] .dot ( recurrent ) + embeddings [ new_word ]\n",
    "            layers.append ( layer )\n",
    "        for i in range ( 1, len ( trues ) ) :\n",
    "            print ( f\"True: { trues [ i ] }  Prediction: { preds [ i ] } \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRAMEWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Tensor (object):\n",
    "    def __init__(self,data, autograd=False,creation_op=None, creators=None, id=None):\n",
    "        self.data=np.array(data)\n",
    "        self.creation_op=creation_op\n",
    "        self.creators=creators\n",
    "        self.grad=None\n",
    "        self.children={}\n",
    "        self.autograd=autograd\n",
    "        if (id is None):\n",
    "            id = np.random.randint(0,100000)\n",
    "        self.id = id\n",
    "        if creators:\n",
    "            for c in creators:\n",
    "                if self.id not in c.children:\n",
    "                    c.children[self.id]=1\n",
    "                else:\n",
    "                    c.children[self.id]+=1\n",
    "    def all_children_grads_accounted_for(self):\n",
    "        for id,cnt in self.children.items():\n",
    "            if(cnt != 0):\n",
    "                return False\n",
    "        return True  \n",
    "    def backward(self, grad, grad_origin=None):\n",
    "        if self.autograd:\n",
    "            if grad_origin is not None:\n",
    "                if not self.children[grad_origin.id]:\n",
    "                    raise Exception(\"Cannnot backprop more than once\")\n",
    "                else:\n",
    "                    self.children[grad_origin.id]-=1\n",
    "            if self.grad is None:\n",
    "                self.grad=grad\n",
    "            else:\n",
    "                self.grad+=grad\n",
    "            if (self.creators is not None) and (grad_origin is None or self.all_children_grads_accounted_for()):\n",
    "                if self.creation_op==\"add\":\n",
    "                    self.creators[0].backward(self.grad, self)\n",
    "                    self.creators[1].backward(self.grad, self)\n",
    "                if self.creation_op==\"transpose\":\n",
    "                    self.creators[0].backward(self.grad.transpose())\n",
    "                if self.creation_op==\"neg\":\n",
    "                    self.creators[0].backward(self.grad.__neg__())\n",
    "                if self.creation_op==\"mul\":\n",
    "                    self.creators[0].backward(self.grad*self.creators[1], self)\n",
    "                    self.creators[1].backward(self.grad*self.creators[0], self)\n",
    "                if self.creation_op==\"sub\":\n",
    "                    self.creators[0].backward(self.grad, self)\n",
    "                    self.creators[1].backward(self.grad.__neg__())\n",
    "                if \"sum\" in self.creation_op:\n",
    "                    dim=int(self.creation_op.split(\"_\")[1])\n",
    "                    ds=self.creators[0].data.shape[dim]\n",
    "                    self.creators[0].backward(self.grad.expand(dim,ds))\n",
    "                if \"expand\" in self.creation_op:\n",
    "                    dim=int(self.creation_op.split(\"_\")[1])\n",
    "                    self.creators[0].backward(self.grad.sum(dim))\n",
    "                if self.creation_op == \"mm\":\n",
    "                    self.creators[0].backward(self.grad.mm(self.creators[1].transpose()))\n",
    "                    self.creators[1].backward(self.grad.transpose().mm(self.creators[0]).transpose())\n",
    "    def __add__(self, other):\n",
    "        if (self.autograd and other.autograd):\n",
    "            return Tensor(self.data+other.data,autograd=True,creation_op=\"add\",creators=[self, other])\n",
    "        return Tensor(self.data+other.data)\n",
    "    def __neg__(self):\n",
    "        if (self.autograd):\n",
    "            return Tensor(self.data * -1, autograd=True, creation_op=\"neg\",creators=[self])\n",
    "        return Tensor(self.data*-1)\n",
    "    def __mul__(self, other):\n",
    "        if (self.autograd and other.autograd):\n",
    "            return Tensor(self.data*other.data,autograd=True,creation_op=\"mul\",creators=[self, other])\n",
    "        return Tensor(self.data*other.data)\n",
    "    def __sub__(self, other):\n",
    "        if (self.autograd and other.autograd):\n",
    "            return Tensor(self.data-other.data,autograd=True,creation_op=\"sub\",creators=[self, other])\n",
    "        return Tensor(self.data-other.data)\n",
    "    def sum(self, dim):\n",
    "        if (self.autograd):\n",
    "            return Tensor(self.data.sum(dim),autograd=True,creation_op=\"sum_\"+str(dim),creators=[self])\n",
    "        return Tensor(self.data.sum(dim))\n",
    "    def mm(self, x):\n",
    "        if (self.autograd and x.autograd):\n",
    "            return Tensor(self.data.dot(x.data),autograd=True,creation_op=\"mm\",creators=[self, x])\n",
    "        return Tensor(self.data.dot(x.data))\n",
    "    def expand(self, dim,copies):\n",
    "\n",
    "        trans_cmd = list(range(0,len(self.data.shape)))\n",
    "        trans_cmd.insert(dim,len(self.data.shape))\n",
    "        new_data = self.data.repeat(copies).reshape(list(self.data.shape) + [copies]).transpose(trans_cmd)\n",
    "        \n",
    "        if(self.autograd):\n",
    "            return Tensor(new_data,autograd=True,creation_op=\"expand_\"+str(dim),creators=[self])\n",
    "        return Tensor(new_data)\n",
    "    \n",
    "    def transpose(self):\n",
    "        if(self.autograd):\n",
    "            return Tensor(self.data.transpose(),autograd=True,creation_op=\"transpose\",creators=[self])\n",
    "        return Tensor(self.data.transpose())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.data.__repr__())\n",
    "    def __str___(self):\n",
    "        return str(self.data__str__())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELS BASED ON FRAMEWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.06643999]\n",
      "[0.49599078]\n",
      "[0.41806719]\n",
      "[0.35298133]\n",
      "[0.29725496]\n",
      "[0.2492326]\n",
      "[0.20785392]\n",
      "[0.17231261]\n",
      "[0.14193745]\n",
      "[0.1161398]\n"
     ]
    }
   ],
   "source": [
    "#Classic approach\n",
    "\n",
    "import numpy\n",
    "np.random.seed(0)\n",
    "\n",
    "data=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "target=np.array([[0],[1],[0],[1]])\n",
    "weights01=np.random.rand(2,3)\n",
    "weights12=np.random.rand(3,1)\n",
    "for i in range (10):\n",
    "    layer0=data\n",
    "    layer1=layer0.dot(weights01)\n",
    "    layer2=layer1.dot(weights12)\n",
    "    diff=layer2-target\n",
    "    sqdiff=diff**2\n",
    "    loss=sqdiff.sum(0)\n",
    "    layer1delta=diff.dot(weights12.transpose())\n",
    "    weights01-=layer0.transpose().dot(layer1delta) * 0.1\n",
    "    weights12-=layer1.transpose().dot(diff) * 0.1\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58128304]\n",
      "[0.48988149]\n",
      "[0.41375111]\n",
      "[0.34489412]\n",
      "[0.28210124]\n",
      "[0.2254484]\n",
      "[0.17538853]\n",
      "[0.1324231]\n",
      "[0.09682769]\n",
      "[0.06849361]\n"
     ]
    }
   ],
   "source": [
    "#Tensor approach\n",
    "\n",
    "import numpy\n",
    "np.random.seed(0)\n",
    "\n",
    "data=Tensor([[0,0],[0,1],[1,0],[1,1]], autograd=True)\n",
    "target=Tensor([[0],[1],[0],[1]], autograd=True)\n",
    "w=list()\n",
    "w.append(Tensor(np.random.rand(2,3), autograd=True))\n",
    "w.append(Tensor(np.random.rand(3,1), autograd=True))\n",
    "for i in range (10):\n",
    "    pred=data.mm(w[0]).mm(w[1])\n",
    "    diff=(pred-target)\n",
    "    sqdiff=diff*diff\n",
    "    loss=sqdiff.sum(0)\n",
    "    loss.backward(Tensor(np.ones_like(loss.data)))\n",
    "    for w_ in w:\n",
    "        w_.data -= w_.grad.data * 0.1\n",
    "        w_.grad.data *= 0\n",
    "    print(loss.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
